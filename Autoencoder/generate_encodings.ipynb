{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a518b31-9d11-4556-ad07-ca53180ab1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 00:01:23.152968: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-25 00:01:23.178481: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-25 00:01:23.617644: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "import os\n",
    "from keras import regularizers\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d102bb6-da5b-497b-b266-45ed1704a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total PID 51- Read the PIDS from the file Spontaneous_PIDs.txt \n",
    "pids = np.loadtxt('../Spontaneous_PIDs_v0.txt')\n",
    "pids.sort()\n",
    "# input for AE will be the linear interpolated data\n",
    "exp_dir = '/home/chinmai/src/Oura/Data/Spontaneous/Lin_IP_GA245_y/'\n",
    "out_dir = '/home/chinmai/src/laborprediction/Autoencoder/ConvAE_GA245_Encodings_y/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f977f0ab-7de6-4b00-917f-27bfa2cc1da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_Autoencoder(enc_dim, in_size):\n",
    "    \n",
    "    # Define the input shape\n",
    "    input_img = keras.Input(shape=(in_size,1))\n",
    "    # ENCODER PART\n",
    "    # First 1D convolutional Layer: 16 filters of length 3 \n",
    "    conv1 = layers.Conv1D(64, 5, activation='LeakyReLU', padding='same', kernel_initializer='glorot_uniform')(input_img)\n",
    "    pool1 = layers.MaxPooling1D(2, padding='same')(conv1)\n",
    "    # Second 1D convolutional Layer: 8 filters of length 3 \n",
    "    conv2 = layers.Conv1D(32, 3, activation='LeakyReLU',padding='same', kernel_initializer='glorot_uniform')(pool1)\n",
    "    pool2 = layers.MaxPooling1D(2, padding='same')(conv2)\n",
    "    # Third 1D convolutional Layer: 16 filters of length 3 \n",
    "    conv3 = layers.Conv1D(16, 3, activation='LeakyReLU', padding='same', kernel_initializer='glorot_uniform')(pool2)\n",
    "    pool3 = layers.MaxPooling1D(2, padding='same')(conv3) \n",
    "    # Flatten the output of all convolutional filters and feed it to a dense fully-connected layer\n",
    "    flat1 = layers.Flatten()(pool3)\n",
    "    # Encoded Representatio of daily temperature data\n",
    "    encoded = layers.Dense(enc_dim,activation='linear', kernel_initializer='glorot_uniform')(flat1)\n",
    "    enc = tf.reshape(encoded,(-1,enc_dim,1))\n",
    "    # Instead of reshaping, we can use the transpose layer on the 64 bit vector.\n",
    "    convT1 = layers.Conv1DTranspose(16, 3,strides=2, padding = 'same', activation = 'LeakyReLU', kernel_initializer='glorot_uniform')(enc)\n",
    "    convT2 = layers.Conv1DTranspose(32, 3,strides=2, padding = 'same', activation = 'LeakyReLU', kernel_initializer='glorot_uniform')(convT1)\n",
    "    convT3 = layers.Conv1DTranspose(64, 5,strides=2, padding = 'same', activation = 'LeakyReLU', kernel_initializer='glorot_uniform')(convT2)\n",
    "    flat2  = layers.Flatten()(convT3)\n",
    "    decoded = layers.Dense(96, activation='linear')(flat2)\n",
    "    \n",
    "    # Keras API allows us to define the model, by specifying the input and final output.\n",
    "    autoencoder = keras.Model(input_img,decoded)\n",
    "    encoder = keras.Model(input_img, encoded)\n",
    "    \n",
    "    return autoencoder, encoder\n",
    "    \n",
    "def create_matrix_from_pids(plist):\n",
    "    global exp_dir, pids\n",
    "    # In this block we want to read 5min avg temperature data for training, validation, and test PIDs\n",
    "    x_arr = []\n",
    "    count = 0\n",
    "\n",
    "    for pid in plist:\n",
    "        fname = os.path.join(exp_dir,str(int(pid))+'_5temp_linIP_y.csv')\n",
    "        #print('Processing pid: ',pid)\n",
    "        data = np.loadtxt(fname,delimiter=',')\n",
    "        d1 = data[:,0:96]\n",
    "        if count == 0:\n",
    "            x_arr = d1\n",
    "        else:\n",
    "            x_arr = np.concatenate((x_arr,d1),axis=0)\n",
    "        #print(x_train.shape)\n",
    "        count += 1\n",
    "    return x_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d672b7cd-0cf7-4245-9434-72b5c78616ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "(29, 64)\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "(20, 64)\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "(32, 64)\n",
      "2/2 [==============================] - 0s 93ms/step\n",
      "(42, 64)\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "(30, 64)\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "(28, 64)\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "(45, 64)\n",
      "2/2 [==============================] - 0s 77ms/step\n",
      "(33, 64)\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "(35, 64)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "(29, 64)\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "(25, 64)\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "(23, 64)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "(23, 64)\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "(41, 64)\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "(40, 64)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "(28, 64)\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "(21, 64)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "(29, 64)\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "(26, 64)\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "(38, 64)\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "(19, 64)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "(20, 64)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "(26, 64)\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "(36, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(38, 64)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "(30, 64)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "(28, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(45, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(33, 64)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "(25, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(41, 64)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "(29, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(41, 64)\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "(24, 64)\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "(47, 64)\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "(16, 64)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "(29, 64)\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "(46, 64)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "(29, 64)\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "(34, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(41, 64)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "(28, 64)\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "(31, 64)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "(25, 64)\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "(28, 64)\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "(43, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(35, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(46, 64)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "(26, 64)\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "(37, 64)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    global pids, exp_dir, out_dir\n",
    "    # Split PIDs to training and validation set\n",
    "    #x_all  = create_matrix_from_pids(pids)\n",
    "    #print(x_all.shape)\n",
    "\n",
    "    # Define the autoencoder model - define_Autoencoder(encoding dimension, input_size)\n",
    "    autoencoder, encoder = define_Autoencoder(64, 288)\n",
    "    #autoencoder= keras.models.load_model('Conv_autoencoder_night_CV.keras')\n",
    "    encoder = keras.models.load_model('./Conv_encoder_all_transpose.keras')\n",
    "    #encoder.summary()\n",
    "    \n",
    "    for pid in pids:\n",
    "        fname = os.path.join(exp_dir,str(int(pid))+'_5temp_linIP_y.csv')\n",
    "        #print('Processing pid: ',pid)\n",
    "        data = np.loadtxt(fname,delimiter=',')\n",
    "        ga = data[:,0:1]\n",
    "        y1 = data[:,-1:]\n",
    "        d1 = data[:,1:289]\n",
    "        \n",
    "        r,c = d1.shape\n",
    "        #print(y1)\n",
    "        #clean_pid.append(pid)\n",
    "        res = encoder.predict(d1)\n",
    "        print (res.shape)\n",
    "        fin = np.concatenate((ga,res,y1),axis = 1)\n",
    "        np.savetxt(out_dir + str(int(pid))+'_5temp_encoding.csv',fin,delimiter=',')\n",
    "    \n",
    "        \n",
    "    #print (clean_pid)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "458bc6f4-ef02-4ce1-83b9-cdfbe716693e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m keras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mset_random_seed(\u001b[38;5;241m912\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mpids\u001b[49m))\n\u001b[1;32m      6\u001b[0m exp_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/chinmai/src/Oura/Data/Linear_Interpolation_y/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m train_pids, test_pids \u001b[38;5;241m=\u001b[39m train_test_split(pids, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pids' is not defined"
     ]
    }
   ],
   "source": [
    "keras.utils.set_random_seed(912)\n",
    "\n",
    "\n",
    "print(len(pids))\n",
    "\n",
    "exp_dir = '/home/chinmai/src/Oura/Data/Linear_Interpolation_y/'\n",
    "train_pids, test_pids = train_test_split(pids, test_size=0.1, random_state=42)\n",
    "\n",
    "train_pids.sort()\n",
    "test_pids.sort()\n",
    "print(train_pids, test_pids)\n",
    "print(len(train_pids),len(test_pids))\n",
    "# We want to further divide the training PIDs to training and Validation PIDs\n",
    "train_pids,val_pids = train_test_split(train_pids, test_size = 0.1, random_state=42)\n",
    "train_pids.sort()\n",
    "print(train_pids, val_pids)\n",
    "print(len(train_pids), len(val_pids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34deb45e-480c-4c1d-a0c2-9110d4ca5146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2267, 288) (250, 288) (295, 288)\n",
      "(2812, 288)\n"
     ]
    }
   ],
   "source": [
    "# In this block we want to read from training and test PIDs\n",
    "x_train = []\n",
    "count = 0\n",
    "for pid in train_pids:\n",
    "    fname = os.path.join(exp_dir,str(pid)+'_5temp_linIP_y.csv')\n",
    "    #print('Processing pid: ',pid)\n",
    "    data = np.loadtxt(fname,delimiter=',')\n",
    "    d1 = data[:,0:288]\n",
    "    if count == 0:\n",
    "        x_train = d1\n",
    "    else:\n",
    "        x_train = np.concatenate((x_train,d1),axis=0)\n",
    "    #print(x_train.shape)\n",
    "    count += 1\n",
    "x_val = []\n",
    "count = 0\n",
    "for pid in val_pids:\n",
    "    fname = os.path.join(exp_dir,str(pid)+'_5temp_linIP_y.csv')\n",
    "    #print('Processing pid: ',pid)\n",
    "    data = np.loadtxt(fname,delimiter=',')\n",
    "    d1 = data[:,0:288]\n",
    "    if count == 0:\n",
    "        x_val = d1\n",
    "    else:\n",
    "        x_val = np.concatenate((x_val,d1),axis=0)\n",
    "    #print(x_train.shape)\n",
    "    count += 1\n",
    "\n",
    "x_test = []\n",
    "count = 0\n",
    "for pid in test_pids:\n",
    "    fname = os.path.join(exp_dir,str(pid)+'_5temp_linIP_y.csv')\n",
    "    #print('Processing pid: ',pid)\n",
    "    data = np.loadtxt(fname,delimiter=',')\n",
    "    d1 = data[:,0:288]\n",
    "    if count == 0:\n",
    "        x_test = d1\n",
    "    else:\n",
    "        x_test = np.concatenate((x_test,d1),axis=0)\n",
    "    #print(x_test.shape)\n",
    "    count += 1\n",
    "print(x_train.shape, x_val.shape, x_test.shape)\n",
    "\n",
    "x_all = []\n",
    "count = 0\n",
    "for pid in pids:\n",
    "    fname = os.path.join(exp_dir,str(pid)+'_5temp_linIP_y.csv')\n",
    "    #print('Processing pid: ',pid)\n",
    "    data = np.loadtxt(fname,delimiter=',')\n",
    "    d1 = data[:,0:288]\n",
    "    if count == 0:\n",
    "        x_all = d1\n",
    "    else:\n",
    "        x_all = np.concatenate((x_all,d1),axis=0)\n",
    "    #print(x_test.shape)\n",
    "    count += 1\n",
    "print (x_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f9a0c7-314a-41b1-b172-4a403bedc211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 12:35:15.861152: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 12:35:15.939123: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 12:35:15.939340: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 12:35:15.941567: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 12:35:15.941763: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 12:35:15.941873: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 12:35:15.980245: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 12:35:15.980377: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 12:35:15.980443: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 12:35:15.980523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14378 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "#autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "encoder = keras.models.load_model('./Conv_encoder.keras')\n",
    "#autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e88ce030-1029-4373-8d5d-5fe886101f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 288, 1)]          0         \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 288, 16)           64        \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPoolin  (None, 144, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 144, 8)            392       \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPoolin  (None, 72, 8)             0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 72, 8)             200       \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPoolin  (None, 36, 8)             0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 288)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                18496     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19152 (74.81 KB)\n",
      "Trainable params: 19152 (74.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.compile(optimizer=keras.optimizers.Adam(), loss='mean_squared_error')\n",
    "encoder.summary()\n",
    "\n",
    "#keras.utils.plot_model(autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89f4c5c8-a631-4d23-8d92-90b523777df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 12:35:34.670046: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 12:35:34.913303: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "res = encoder.predict(x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a06c504-9b1c-41f3-ac17-a30c8352dc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3742c7af-405f-462c-ae14-2e6cdcf386d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "(46, 64)\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "(73, 64)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(32, 64)\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "(71, 64)\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "(66, 64)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "(28, 64)\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "(67, 64)\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "(72, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(44, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(45, 64)\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "(87, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(52, 64)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "(23, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(55, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(50, 64)\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "(70, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(55, 64)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "(29, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(37, 64)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "(26, 64)\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "(58, 64)\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "(29, 64)\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "(47, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(46, 64)\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "(63, 64)\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "(46, 64)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "(30, 64)\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "(65, 64)\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "(51, 64)\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "(68, 64)\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "(49, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(58, 64)\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "(83, 64)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "(29, 64)\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "(43, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(45, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(55, 64)\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "(65, 64)\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "(39, 64)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "(29, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(53, 64)\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "(75, 64)\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "(38, 64)\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "(72, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(56, 64)\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "(40, 64)\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "(71, 64)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "(25, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(53, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(45, 64)\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "(42, 64)\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "(54, 64)\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "(87, 64)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "(26, 64)\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "(49, 64)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "clean_pid =[]\n",
    "for pid in pids:\n",
    "    fname = os.path.join(exp_dir,str(pid)+'_5temp_linIP_y.csv')\n",
    "    #print('Processing pid: ',pid)\n",
    "    data = np.loadtxt(fname,delimiter=',')\n",
    "    y1 = data[:,-1:]\n",
    "    d1 = data[:,0:288]\n",
    "    r,c = d1.shape\n",
    "    #print(y1)\n",
    "    #clean_pid.append(pid)\n",
    "    res = encoder.predict(d1)\n",
    "    print (res.shape)\n",
    "    fin = np.concatenate((res,y1),axis = 1)\n",
    "    np.savetxt('./ConvAE_LinIP_Encodings_y/'+str(pid)+'_5temp_encoding.csv',fin,delimiter=',')\n",
    "\n",
    "    #print (clean_pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfc781f-cd63-4d1f-a198-4cb6e01c9211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
