{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3530bba-1a90-49ae-bd01-b7c2ae24421a",
   "metadata": {},
   "source": [
    "To verify the saved model checkpoint, we will load the model weights and test it on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a19779c-b91b-4eac-be48-36b4ce055dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 14:45:54.533632: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-29 14:45:54.712109: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-29 14:45:55.439114: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_PROFILE=uaprofile\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "import os\n",
    "from keras import regularizers\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "%set_env AWS_PROFILE=uaprofile\n",
    "from sensorfabric.athena import athena\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "db = athena(database='elise', offlineCache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e673bcb-39e7-4619-8d09-c9e8a256b86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 7, 10, 11, 15, 29, 35, 36, 48, 55, 61, 67, 69, 72, 73, 75, 76, 77, 80, 88, 90, 91, 93, 97, 99, 102, 104, 106, 107, 108, 110, 111, 113, 120, 124, 126, 129, 136, 138, 141, 144, 152, 156, 161, 170, 183, 189] [173, 179, 191, 193, 195, 197]\n",
      "48 6\n",
      "[129, 67, 80, 11, 99, 36, 10, 29, 138, 113, 69, 76, 170, 73, 48, 75, 107, 111, 183, 1, 110, 108, 15, 61, 120, 2, 161, 90, 7, 126, 124, 93, 144, 55, 91, 77, 189, 88, 35, 152, 72, 106, 136] [97, 102, 104, 141, 156]\n",
      "43 5\n"
     ]
    }
   ],
   "source": [
    "#keras.utils.set_random_seed(912)\n",
    "\n",
    "# 45 spontaneous PIDs having at least 21 days of temperature data prior to labor date.\n",
    "# FOLD \n",
    "train_pids = [15, 67, 80, 161, 183, 189, 1, 2, 7, 10, 11, 29, 35, 36, 48, 55, 61, 69, 72, 73, 75, 76, 77, 88, 90, 91, 93, 97, 99, 102, \n",
    "              104, 106, 107, 108, 110, 111, 113, 120, 124, 126, 129, 136, 138, 141, 144, 152, 156, 170 ]\n",
    "\n",
    "test_pids = [173, 179, 191, 193, 195, 197]\n",
    "\n",
    "data_dir = '/home/chinmai/src/Oura/Data/ConvAE_LinIP_Encodings_40LD_y'\n",
    "#exp_dir  = '/home/chinmai/src/Oura/Data/Linear_Interpolation_y/'\n",
    "\n",
    "train_pids.sort()\n",
    "test_pids.sort()\n",
    "print(train_pids, test_pids)\n",
    "print(len(train_pids),len(test_pids))\n",
    "\n",
    "# We want to further divide the training PIDs to training and Validation PIDs\n",
    "train_pids,val_pids = train_test_split(train_pids, test_size = 0.1, random_state=42)\n",
    "val_pids.sort()\n",
    "print(train_pids, val_pids)\n",
    "print(len(train_pids), len(val_pids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b04e8457-7a99-47ba-843c-921095721380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 52, 64) (5, 52, 64) (6, 52, 64)\n",
      "(43, 52, 1) (5, 52, 1) (6, 52, 1)\n"
     ]
    }
   ],
   "source": [
    "# In this block we want to read from training and test PIDs\n",
    "# Reading the ConvAE encodings as input and days to labor as output.\n",
    "x_train = []\n",
    "y_train = []\n",
    "count = 0\n",
    "mlen = 0\n",
    "for pid in train_pids:\n",
    "    fname = os.path.join(data_dir,str(pid)+'_5temp_encoding_40LD.csv')\n",
    "    #print('Processing pid: ',pid)\n",
    "    data = np.loadtxt(fname,delimiter=',')\n",
    "    d1 = data[:,0:64]\n",
    "    d2 = data[:,-1]\n",
    "    mr,mc = data.shape\n",
    "    if (mr > mlen):\n",
    "        mlen = mr\n",
    "    x_train.append(d1)\n",
    "    y_train.append(d2)\n",
    "    count += 1\n",
    "\n",
    "x_val = []\n",
    "y_val = []\n",
    "count = 0\n",
    "for pid in val_pids:\n",
    "    fname = os.path.join(data_dir,str(pid)+'_5temp_encoding_40LD.csv')\n",
    "    #print('Processing pid: ',pid)\n",
    "    data = np.loadtxt(fname,delimiter=',')\n",
    "    d1 = data[:,0:64]\n",
    "    d2 = data[:,-1]\n",
    "    if (mr > mlen):\n",
    "        mlen = mr\n",
    "    x_val.append(d1)\n",
    "    y_val.append(d2)\n",
    "    count += 1\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "count = 0\n",
    "for pid in test_pids:\n",
    "    fname = os.path.join(data_dir,str(pid)+'_5temp_encoding_40LD.csv')\n",
    "    #print('Processing pid: ',pid)\n",
    "    data = np.loadtxt(fname,delimiter=',')\n",
    "    d1 = data[:,0:64]\n",
    "    d2 = data[:,-1]\n",
    "    if (mr > mlen):\n",
    "        mlen = mr\n",
    "    x_test.append(d1)\n",
    "    y_test.append(d2)\n",
    "    count += 1\n",
    "\n",
    "#print(mlen)\n",
    "\n",
    "# Maximum length will no longer be 40. It is infact 52\n",
    "x_tr_pad = pad_sequences(x_train, dtype='float32', maxlen=mlen, padding='post')\n",
    "y_tr_pad = pad_sequences(y_train, dtype='float32', maxlen=mlen, padding='post')\n",
    "x_tr = np.asarray(x_tr_pad)\n",
    "y_tr = np.asarray(y_tr_pad)\n",
    "\n",
    "a,b = y_tr.shape\n",
    "y_tr = np.reshape(y_tr,(a,b,1))\n",
    "\n",
    "    \n",
    "x_va_pad = pad_sequences(x_val, dtype='float32', maxlen=mlen, padding='post')\n",
    "y_va_pad = pad_sequences(y_val, dtype='float32', maxlen=mlen, padding='post')\n",
    "x_va = np.asarray(x_va_pad)\n",
    "y_va = np.asarray(y_va_pad)\n",
    "a,b = y_va.shape\n",
    "y_va = np.reshape(y_va,(a,b,1))\n",
    "\n",
    "\n",
    "x_te_pad = pad_sequences(x_test, dtype='float32', maxlen=mlen, padding='post')\n",
    "y_te_pad = pad_sequences(y_test, dtype='float32', maxlen=mlen, padding='post')\n",
    "\n",
    "x_te = np.asarray(x_te_pad)\n",
    "y_te = np.asarray(y_te_pad)\n",
    "\n",
    "a,b = y_te.shape\n",
    "y_te = np.reshape(y_te,(a,b,1))\n",
    "\n",
    "\n",
    "print(x_tr.shape, x_va.shape, x_te.shape)\n",
    "print(y_tr.shape, y_va.shape, y_te.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3feaf47f-1b79-4bee-98e1-28e343a8b962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.set_random_seed(912)\n",
    "# LSTM model\n",
    "input_img = keras.Input(shape=[mlen,64])\n",
    "m1 = layers.Masking(mask_value = 0)(input_img)\n",
    "\n",
    "l1 = layers.LSTM(128,activation = 'tanh', use_bias=True, kernel_initializer=\"glorot_uniform\",\n",
    "                 recurrent_initializer=\"orthogonal\", bias_initializer=\"zeros\", return_sequences = True, unroll = True)\n",
    "#nl1 = layers.LayerNormalization(axis=1)(l1)\n",
    "x = l1(m1)\n",
    "ln1 = layers.LayerNormalization(axis=1)(x)\n",
    "d0 = layers.Dense(128,activation='LeakyReLU', kernel_initializer='glorot_uniform')(ln1)\n",
    "# LSTM \n",
    "d1 = layers.Dense(1,activation='linear', kernel_initializer='glorot_uniform')(d0)\n",
    "\n",
    "#print(x.shape)\n",
    "#print(d1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d06df060-dadf-4c21-8334-2533c7ce04a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 52, 64)]          0         \n",
      "                                                                 \n",
      " masking_4 (Masking)         (None, 52, 64)            0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 52, 128)           98816     \n",
      "                                                                 \n",
      " layer_normalization_4 (Lay  (None, 52, 128)           104       \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 52, 128)           16512     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 52, 1)             129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115561 (451.41 KB)\n",
      "Trainable params: 115561 (451.41 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.utils.set_random_seed(912)\n",
    "simple_lstm = keras.Model(input_img,d1)\n",
    "simple_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37b857aa-7b62-40b3-bd0e-0e4ece6b334d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 19 variables. \n"
     ]
    }
   ],
   "source": [
    "keras.utils.set_random_seed(912)\n",
    "# MAE loss - mean(abs(true Temperature - reconstructed Temprature from encoding))\n",
    "simple_lstm.compile(optimizer=keras.optimizers.Adam(), loss='mean_absolute_error')\n",
    "simple_lstm.load_weights('./fold9_40LD/final_weights.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60b8b647-2f22-4f22-b98d-66e59fee3b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff51c105a20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff51c105a20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 530ms/step - loss: 6.1379\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2400\n"
     ]
    }
   ],
   "source": [
    "# Run the Evaluate function on the test dataset.\n",
    "res = simple_lstm.evaluate(x_va,y_va)\n",
    "res = simple_lstm.evaluate(x_te,y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8f93d1d-23e3-4b79-bd44-1e2a3d7244a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff51c107490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff51c107490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 514ms/step\n"
     ]
    }
   ],
   "source": [
    "#res = simple_lstm.evaluate(x_te,y_te)\n",
    "pred = simple_lstm.predict(x_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "85bc3513-3876-4566-82ed-528ec15be67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "[12.254083633422852, 9.986349105834961, 11.946474075317383, 11.159368515014648, 9.401437759399414, 8.756692886352539, 10.50056266784668, 6.639898300170898, 9.764425277709961, 9.599466323852539, 6.015737533569336, 7.069204330444336, 7.360784530639648, 5.826555252075195, 6.824136734008789, 7.385988235473633, 0.5139942169189453, 1.377302646636963, 0.32809972763061523, 2.6384990215301514, 2.0540270805358887, 2.5589375495910645, 0.7432856559753418, 0.0007073879241943359, 3.2909746170043945]\n",
      "34\n",
      "[2.3505306243896484, 2.784198760986328, 0.5671100616455078, 0.3721961975097656, 0.5926876068115234, 0.11930274963378906, 0.7735309600830078, 0.9791412353515625, 2.7908992767333984, 3.3972854614257812, 3.322225570678711, 1.9994487762451172, 2.639925003051758, 1.989328384399414, 0.33205604553222656, 1.131692886352539, 0.9049148559570312, 1.7312631607055664, 1.3524885177612305, 0.845942497253418, 1.6649904251098633, 1.0862865447998047, 0.22890186309814453, 2.1606645584106445, 2.8852953910827637, 2.3113837242126465, 1.0882205963134766, 0.5603752136230469, 0.506256103515625, 2.804487705230713, 1.3985986709594727, 1.2212677001953125, 2.24357271194458, 2.128964424133301]\n",
      "40\n",
      "[8.323431015014648, 4.590328216552734, 4.49359130859375, 3.1596221923828125, 2.502391815185547, 4.427484512329102, 4.819433212280273, 3.3563995361328125, 1.9783306121826172, 3.6862964630126953, 2.2119617462158203, 2.9914798736572266, 2.945810317993164, 1.8908100128173828, 2.277547836303711, 1.792917251586914, 2.128854751586914, 3.0002574920654297, 3.6623878479003906, 4.354574203491211, 2.4363269805908203, 3.1188783645629883, 3.381061553955078, 3.7414684295654297, 3.851485252380371, 2.4273500442504883, 3.9382104873657227, 2.4999170303344727, 5.02805757522583, 3.75581693649292, 4.312373638153076, 3.495145320892334, 2.8440027236938477, 3.5163700580596924, 0.9935746192932129, 0.538733959197998, 1.5819692611694336, 0.4408590793609619, 3.7699079513549805, 3.6414480209350586]\n",
      "52\n",
      "[16.692401885986328, 17.440261840820312, 16.840118408203125, 15.774417877197266, 16.86484718322754, 15.397865295410156, 18.372360229492188, 16.050216674804688, 16.88411521911621, 17.83114242553711, 14.732990264892578, 15.436241149902344, 15.120014190673828, 13.94171142578125, 14.89975357055664, 14.011920928955078, 13.088363647460938, 14.304208755493164, 12.532154083251953, 12.662982940673828, 11.844154357910156, 12.294322967529297, 11.372356414794922, 10.939651489257812, 12.2073392868042, 11.873302459716797, 11.320660591125488, 10.893285751342773, 10.42031478881836, 9.390711784362793, 10.705241203308105, 12.617317199707031, 12.589550018310547, 12.818403244018555, 10.458404541015625, 9.623117446899414, 7.877933025360107, 8.735641479492188, 7.796483039855957, 7.109941005706787, 6.4889092445373535, 6.096554279327393, 6.006959438323975, 3.2324328422546387, 5.123762607574463, 1.0585017204284668, 1.2497057914733887, 0.4170866012573242, 0.7438671588897705, 1.439871072769165, 1.3375911712646484, 2.0675876140594482]\n",
      "26\n",
      "[6.827302932739258, 9.889543533325195, 11.581514358520508, 12.616044998168945, 8.999652862548828, 8.95924186706543, 7.429937362670898, 7.769521713256836, 9.053586959838867, 8.166845321655273, 6.19053840637207, 7.926008224487305, 5.786535263061523, 5.691919326782227, 6.813146591186523, 3.934922218322754, 2.2293195724487305, 1.7723264694213867, 1.0951733589172363, 0.2511568069458008, 1.2567062377929688, 0.2385997772216797, 1.7069091796875, 1.529167652130127, 2.5120229721069336, 2.850163459777832]\n",
      "42\n",
      "[4.806499481201172, 2.3794479370117188, 1.6362228393554688, 6.465740203857422, 3.8098602294921875, 1.351806640625, 1.6470108032226562, 3.022714614868164, 2.3839263916015625, 3.6921768188476562, 4.136861801147461, 4.367155075073242, 4.902156829833984, 2.540792465209961, 1.8325824737548828, 0.6597957611083984, 2.775697708129883, 3.3977928161621094, 0.5642032623291016, 0.7227115631103516, 2.4823436737060547, 1.912811279296875, 0.16869544982910156, 2.440349578857422, 0.7613105773925781, 0.9251070022583008, 1.8664636611938477, 2.711543083190918, 6.4354352951049805, 5.322661876678467, 3.949519634246826, 3.6430211067199707, 2.5546841621398926, 3.6455588340759277, 2.8700108528137207, 1.6187858581542969, 0.2140789031982422, 0.7300963401794434, 1.8329405784606934, 1.889601707458496, 2.600376605987549, 4.615025997161865]\n"
     ]
    }
   ],
   "source": [
    "# Length of test set\n",
    "te_len = len(test_pids)\n",
    "err_list = []\n",
    "err_avg_list = []\n",
    "for i in range(0,te_len):\n",
    "\n",
    "    err = []\n",
    "    trim_0 = [x for x in y_te[i] if x!= 0]\n",
    "    print(len(trim_0))\n",
    "    \n",
    "    days = len(trim_0)\n",
    "    for j in range(0,days):\n",
    "        err.append(abs(float(y_te[i][j] - pred[i][j])))\n",
    "\n",
    "    #print(days)\n",
    "    #print(pred.shape)\n",
    "    print(err)\n",
    "    avg = sum(err)/len(err)\n",
    "    err_list.append(err)\n",
    "    err_avg_list.append(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "77634950-e135-462d-a89e-77ddeb38e6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.159879722595215, 1.5666304195628447, 3.197671687602997, 10.712097108364105, 5.502992593325102, 2.67346613747733]\n",
      "4.968789611487932\n"
     ]
    }
   ],
   "source": [
    "print(err_avg_list)\n",
    "print(sum(err_avg_list)/len(err_avg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "76459b7e-0fe9-4205-b99e-c6380a2d460b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID:  173\n",
      "Before: 0 40\n",
      "PID:  179\n",
      "Before: 6 34\n",
      "PID:  191\n",
      "Before: 0 40\n",
      "PID:  193\n",
      "After: 12 52\n",
      "PID:  195\n",
      "Before: 2 38\n",
      "PID:  197\n",
      "After: 2 42\n"
     ]
    }
   ],
   "source": [
    "# PIDs with EDD error.\n",
    "edd_err_pids = [71, 72, 75, 123, 138]\n",
    "\n",
    "# Writing Individual CSV Files to FOLD folder.\n",
    "# Length of test set\n",
    "te_len = len(test_pids)\n",
    "err_list = []\n",
    "err_avg_list = []\n",
    "# Flag to indicate Before and After EDD\n",
    "before = 0\n",
    "\n",
    "for i in range(0,te_len):\n",
    "    p = str(test_pids[i])\n",
    "    print('PID: ', p)\n",
    "    fname = './Spontaneous_Model_Predictions_40LD/'+str(p)+'.csv'\n",
    "    #print(fname)\n",
    "    fd = open(fname,'w')\n",
    "    \n",
    "    # 1st Line is the PID\n",
    "    fd.write('PID '+ p +'\\n')\n",
    "    \n",
    "    # First: We need to calculate the relative distance from EDD\n",
    "    # Get the labor date for the PID from the enroll_labor table\n",
    "    query2 = 'select edd, labordate from edd_laboronset where pid = {pid}'\n",
    "    res2   = db.execQuery(query2.format(pid=p), cached=True)\n",
    "    \n",
    "    labordate = pd.to_datetime(res2['labordate'][0])\n",
    "    #print ('Labor date for pid: ',p,' is ',labordate)\n",
    "\n",
    "    edd = pd.to_datetime(res2['edd'][0])\n",
    "    #print ('EDD for pid: ',p,' is ',edd)\n",
    "    \n",
    "     # Make the Error correction in EDD\n",
    "    if pid in edd_err_pids:\n",
    "        edd = edd + timedelta(days = 365)\n",
    "        #print('EDD error corrected for pid ',pid,'. EDD is ',edd)\n",
    "\n",
    "    # Calculate the difference between EDD and laboronset.\n",
    "    if edd < labordate:\n",
    "        # Before = 0\n",
    "        # AFTER EDD\n",
    "        # Get the difference in days from EDD to laboronset.\n",
    "        dd = (labordate - edd).days\n",
    "        val = 40 + dd\n",
    "        print ('After:',dd, val)\n",
    "        \n",
    "    else:        # This means that EDD is >= Labordate\n",
    "        # BEFORE\n",
    "        before = 1\n",
    "        # Get the difference in days from EDD to laboronset.\n",
    "        dd = (edd-labordate).days\n",
    "        val = 40-dd\n",
    "        print ('Before:',dd, val)\n",
    "    \n",
    "    \n",
    "    # Remove all zeros from y_te and pred[i] and reshapee pred[i] to be a vector\n",
    "    trim_y_te = [float(x) for x in y_te[i] if x!= 0]\n",
    "    trim_pred_i = pred[i][0:len(trim_y_te)]\n",
    "    trim_pred_i = np.reshape(trim_pred_i,(len(trim_pred_i),))\n",
    "    \n",
    "    # Cieling of the first y value is the total available days of data.\n",
    "    # This depends whether the labor happened before of after EDD.\n",
    "    #cei_y = math.ceil(trim_y_te[0])\n",
    "    #print(cei_y)\n",
    "    \n",
    "    fd.write('Days Before Labor ,')\n",
    "    for j in range(len(trim_y_te),1,-1):    # Write from 240 to maximum length of sequence.\n",
    "        fd.write(str(j)+',')\n",
    "    fd.write(str(j-1)+'\\n')\n",
    "    \n",
    "    \n",
    "    # 3rd Line - Ground Truth\n",
    "    fd.write('Ground Truth ,')\n",
    "    for j in range(0,len(trim_y_te)-1):\n",
    "        fd.write(str(float(trim_y_te[j]))+',')\n",
    "    fd.write(str(float(trim_y_te[j+1]))+'\\n')\n",
    "\n",
    "    # 4th Line - Ground Truth\n",
    "    fd.write('Model Prediction ,')\n",
    "    for j in range(0,len(trim_pred_i)-1):\n",
    "        fd.write(str(float(trim_pred_i[j]))+',')\n",
    "    fd.write(str(float(trim_pred_i[j+1]))+'\\n')\n",
    "    \n",
    "    err = []\n",
    "    abs_err = []\n",
    "    days = len(trim_y_te)\n",
    "    for j in range(0,days):\n",
    "        abs_err.append(abs(float(trim_y_te[j] - trim_pred_i[j])))\n",
    "        err.append(float(trim_y_te[j] - trim_pred_i[j]))\n",
    "\n",
    "    # 5th Line\n",
    "    fd.write('Error ,')\n",
    "    for j in range(0,len(err)-1):\n",
    "        fd.write(str(float(err[j]))+',')\n",
    "    fd.write(str(float(err[j+1]))+'\\n')\n",
    "\n",
    "    # 6th Line\n",
    "    fd.write('Absolute Error ,')\n",
    "    for j in range(0,len(abs_err)-1):\n",
    "        fd.write(str(float(abs_err[j]))+',')\n",
    "    fd.write(str(float(abs_err[j+1]))+'\\n')\n",
    "\n",
    "    # 7th Line\n",
    "    fd.write('Mean Absolute Error ,')\n",
    "    fd.write(str(float(sum(abs_err)/len(abs_err)))+'\\n')\n",
    "\n",
    "    fd.close()\n",
    "    \n",
    "    #print(days)\n",
    "    #print(pred.shape)\n",
    "    #print(err)\n",
    "    #avg = sum(err)/len(err)\n",
    "    #err_list.append(err)\n",
    "    #err_avg_list.append(avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10373dce-49f3-4bdb-8d57-da4dc9b3f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(act_pred))\n",
    "print(y_tr.shape)\n",
    "for i in range(0,len(act_pred)): \n",
    "    x = act_pred[i] - y_tr[i]\n",
    "    print(x)\n",
    "    \n",
    "#print(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95abc62c-87e1-45b3-a090-97d959b786b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
