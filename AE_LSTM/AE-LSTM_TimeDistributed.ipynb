{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf0d2d66-0d31-441d-8e0d-fa52e1ee6cd7",
   "metadata": {},
   "source": [
    "# AE LSTM for Spontaneous Using all temp data.\n",
    "We will execute the AE-LSTM code for Spontaneous using entire days' data.\n",
    "From previous version of AE-LSTM code, we will use a time distributed dense layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0739502-cb42-492e-8cb6-fa207d9a6863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 18:16:10.787881: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-24 18:16:10.812584: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-24 18:16:11.247393: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "keras.utils.set_random_seed(912)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "173be2e3-22d9-483b-86fa-19924276aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total PID 51- Read the PIDS from the file Spontaneous_PIDs.txt \n",
    "pids = np.loadtxt('../Spontaneous_PIDs_v0.txt')\n",
    "pids.sort()\n",
    "\n",
    "exp_dir = '/home/chinmai/src/laborprediction/Autoencoder/ConvAE_GA245_Encodings_y'\n",
    "max_seq_len = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0989f9a7-7287-4d72-b808-522726220eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix_from_pid(plist):\n",
    "    global exp_dir, max_seq_len\n",
    "    # In this block we want to read 5min avg temperature data for training, validation, and test PIDs\n",
    "    x_arr = []\n",
    "    y_arr = []\n",
    "    count = 0\n",
    "    for pid in plist:\n",
    "        fname = os.path.join(exp_dir,str(int(pid))+'_5temp_encoding.csv')\n",
    "        #print('Processing pid: ',pid)\n",
    "        data = np.loadtxt(fname,delimiter=',')\n",
    "        mr,mc = data.shape\n",
    "        # 0: Gestational Age, 1:97 - Temperature Data, 98 - Days to Labor \n",
    "        # NOTE: July 12, setting this value from 1:17 insteaf of 0:17 excludes\n",
    "        # gestational age as a feature.\n",
    "        d1 = data[:,1:65]\n",
    "        d2 = data[:,65:]\n",
    "        if np.isnan(d1).any():\n",
    "            print(f\"PID={pid} has NaN values\")\n",
    "        # Adjust the maximum length of the sequence.\n",
    "        if mr > max_seq_len:\n",
    "            max_seq_len = mr\n",
    "        #print('Max Seq Len :',max_seq_len)\n",
    "        x_arr.append(d1)\n",
    "        y_arr.append(d2)\n",
    "    \n",
    "        count += 1\n",
    "    \"\"\"\n",
    "    x_pad = pad_sequences(x_arr, maxlen=max_len, dtype='float32', padding='post', value=0.0)\n",
    "    y_pad = pad_sequences(y_arr, maxlen=max_len, dtype='float32', padding='post', value=0.0)\n",
    "    x_arr_pad = np.asarray(x_pad)\n",
    "    y_arr_pad = np.asarray(y_pad)\n",
    "    print(x_arr_pad.shape)\n",
    "    \"\"\"\n",
    "    return x_arr, y_arr\n",
    "\n",
    "def add_padding (x_list):\n",
    "    global max_seq_len\n",
    "    x_pad = pad_sequences(x_list, maxlen=max_seq_len, dtype='float32', padding='post', value=0.)\n",
    "    x_arr_pad = np.asarray(x_pad)\n",
    "    return x_arr_pad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1a3b2d6-71f4-4de2-a606-e12e437cd894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_lstm(seq_len, enc_dim):\n",
    "    # To this function, we will pass the sequence length and the encoding dimension.\n",
    "    input_seq = keras.Input(shape=[seq_len,enc_dim])    # Shape =[47,16]\n",
    "    m1 = layers.Masking(mask_value = 0.)(input_seq)\n",
    "    #l1 = layers.LSTM(4,activation = 'tanh', use_bias=True, kernel_initializer=\"glorot_uniform\",\n",
    "    #             recurrent_initializer=\"orthogonal\", bias_initializer=\"zeros\", return_sequences = True)(m1)\n",
    "    l1 = layers.LSTM(256,activation = 'tanh', return_sequences = True)(m1)\n",
    "    ln1 = layers.LayerNormalization(axis=1)(l1)\n",
    "    #x   = l1(m1)\n",
    "    #ln1 = layers.LayerNormalization(axis=1)(x)\n",
    "    d0 = layers.TimeDistributed(layers.Dense(128,activation='LeakyReLU', kernel_initializer='glorot_uniform'))(ln1)\n",
    "    o1 = layers.TimeDistributed(layers.Dense(1,activation='linear', kernel_initializer='glorot_uniform'))(d0)\n",
    "    lstm = keras.Model(input_seq,o1)\n",
    "    return lstm\n",
    "    #d1 = layers.Dense(1,activation='linear', kernel_initializer='glorot_uniform')(d0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95834541-49ff-4fc4-b30e-26880e6fb6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "[15.0, 29.0, 35.0, 36.0, 48.0, 55.0, 61.0, 67.0, 69.0, 72.0, 73.0, 75.0, 77.0, 80.0, 88.0, 90.0, 91.0, 93.0, 97.0, 99.0, 102.0, 106.0, 107.0, 108.0, 110.0, 111.0, 113.0, 120.0, 126.0, 129.0, 136.0, 138.0, 141.0, 144.0, 152.0, 156.0, 161.0, 170.0, 173.0, 179.0] [183.0, 191.0, 193.0, 195.0, 197.0]\n",
      "[1.0, 2.0, 7.0, 10.0, 11.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 18:16:16.202923: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-07-24 18:16:16.202942: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: chinmai-x17\n",
      "2024-07-24 18:16:16.202945: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: chinmai-x17\n",
      "2024-07-24 18:16:16.203056: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.183.6\n",
      "2024-07-24 18:16:16.203065: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.183.6\n",
      "2024-07-24 18:16:16.203067: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 535.183.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 47, 64)]          0         \n",
      "                                                                 \n",
      " masking (Masking)           (None, 47, 64)            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 47, 256)           328704    \n",
      "                                                                 \n",
      " layer_normalization (Layer  (None, 47, 256)           94        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, 47, 128)           32896     \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, 47, 1)             129       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 361823 (1.38 MB)\n",
      "Trainable params: 361823 (1.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 41ms/step - loss: 13.6635 - val_loss: 14.2008\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 8.1581 - val_loss: 10.6434\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.6371 - val_loss: 9.1815\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.4352 - val_loss: 7.4300\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 4.8102 - val_loss: 6.5163\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.0389 - val_loss: 6.8210\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.9942 - val_loss: 6.3970\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 4.2034 - val_loss: 6.7358\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.4152 - val_loss: 5.9560\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.1303 - val_loss: 4.9823\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.9681 - val_loss: 4.7397\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.6263 - val_loss: 4.3206\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 3.4907 - val_loss: 7.1884\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 3.0769 - val_loss: 4.4608\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 2.5925 - val_loss: 6.4584\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 2.6414 - val_loss: 4.9701\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.4349 - val_loss: 5.3359\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.3489 - val_loss: 4.2660\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 2.1014 - val_loss: 5.7004\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.8705 - val_loss: 3.9090\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.8436 - val_loss: 5.7680\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.7731 - val_loss: 3.1518\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.7242 - val_loss: 5.9547\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.5368 - val_loss: 4.3193\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.3279 - val_loss: 4.5873\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.3502 - val_loss: 3.2412\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.1734 - val_loss: 5.1688\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 1.8195 - val_loss: 3.8586\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.6034 - val_loss: 5.5760\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.5462 - val_loss: 5.1502\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.5102 - val_loss: 2.9122\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.3363 - val_loss: 3.1029\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.3182 - val_loss: 3.9613\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.0696 - val_loss: 4.5106\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.0405 - val_loss: 3.6360\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.4317 - val_loss: 6.0861\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 1.7862 - val_loss: 4.1459\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.6017 - val_loss: 3.0191\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.5427 - val_loss: 5.8776\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 1.4158 - val_loss: 3.2418\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.3282 - val_loss: 4.4822\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.4618\n",
      "1/1 [==============================] - 0s 439ms/step\n",
      "4.461785316467285\n",
      "(5, 47, 1)\n",
      "Fold 1:\n",
      "[1.0, 2.0, 7.0, 10.0, 11.0, 55.0, 61.0, 67.0, 69.0, 72.0, 73.0, 75.0, 77.0, 80.0, 88.0, 90.0, 91.0, 93.0, 97.0, 99.0, 102.0, 106.0, 107.0, 108.0, 110.0, 111.0, 113.0, 120.0, 126.0, 129.0, 136.0, 138.0, 141.0, 144.0, 152.0, 156.0, 161.0, 170.0, 173.0, 179.0] [183.0, 191.0, 193.0, 195.0, 197.0]\n",
      "[15.0, 29.0, 35.0, 36.0, 48.0]\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 47, 64)]          0         \n",
      "                                                                 \n",
      " masking_1 (Masking)         (None, 47, 64)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 47, 256)           328704    \n",
      "                                                                 \n",
      " layer_normalization_1 (Lay  (None, 47, 256)           94        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDi  (None, 47, 128)           32896     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDi  (None, 47, 1)             129       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 361823 (1.38 MB)\n",
      "Trainable params: 361823 (1.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 39ms/step - loss: 12.6008 - val_loss: 13.4061\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 7.5833 - val_loss: 9.9424\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.8131 - val_loss: 7.4676\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.0642 - val_loss: 7.2909\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.0118 - val_loss: 6.7020\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.3196 - val_loss: 7.3176\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.1698 - val_loss: 6.4670\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.1213 - val_loss: 6.9062\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 3.8125 - val_loss: 5.4976\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 3.2893 - val_loss: 6.1323\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 2.8951 - val_loss: 5.0650\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.7881 - val_loss: 5.2289\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.6770 - val_loss: 5.5591\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 3.0377 - val_loss: 6.5806\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.4745 - val_loss: 4.3076\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1880 - val_loss: 4.7359\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.0544 - val_loss: 3.9353\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1653 - val_loss: 4.0053\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.2937 - val_loss: 5.1768\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.0505 - val_loss: 4.3849\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 1.8482 - val_loss: 4.4965\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.5049 - val_loss: 4.3844\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.8450 - val_loss: 3.7066\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.7125 - val_loss: 4.5580\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.6504 - val_loss: 5.6019\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.6962 - val_loss: 3.9622\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.3016 - val_loss: 5.6285\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.4875 - val_loss: 4.2913\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.2735 - val_loss: 3.7482\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.1272 - val_loss: 4.5619\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.1844 - val_loss: 4.5803\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.2298 - val_loss: 3.9125\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.0223 - val_loss: 3.9774\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.9679\n",
      "1/1 [==============================] - 0s 434ms/step\n",
      "3.96787691116333\n",
      "(5, 47, 1)\n",
      "Fold 2:\n",
      "[1.0, 2.0, 7.0, 10.0, 11.0, 15.0, 29.0, 35.0, 36.0, 48.0, 73.0, 75.0, 77.0, 80.0, 88.0, 90.0, 91.0, 93.0, 97.0, 99.0, 102.0, 106.0, 107.0, 108.0, 110.0, 111.0, 113.0, 120.0, 126.0, 129.0, 136.0, 138.0, 141.0, 144.0, 152.0, 156.0, 161.0, 170.0, 173.0, 179.0] [183.0, 191.0, 193.0, 195.0, 197.0]\n",
      "[55.0, 61.0, 67.0, 69.0, 72.0]\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 47, 64)]          0         \n",
      "                                                                 \n",
      " masking_2 (Masking)         (None, 47, 64)            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 47, 256)           328704    \n",
      "                                                                 \n",
      " layer_normalization_2 (Lay  (None, 47, 256)           94        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDi  (None, 47, 128)           32896     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDi  (None, 47, 1)             129       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 361823 (1.38 MB)\n",
      "Trainable params: 361823 (1.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 40ms/step - loss: 12.3806 - val_loss: 13.0048\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 7.4003 - val_loss: 10.2240\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.9814 - val_loss: 9.4632\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 4.6850 - val_loss: 7.1264\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 4.0064 - val_loss: 6.2459\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 4.7275 - val_loss: 7.5824\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.8578 - val_loss: 6.9349\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.5772 - val_loss: 7.4912\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.7120 - val_loss: 5.3658\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.3380 - val_loss: 5.8369\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.1113 - val_loss: 6.0583\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.2588 - val_loss: 5.1723\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.2531 - val_loss: 7.3232\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 2.7628 - val_loss: 6.3048\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.6075 - val_loss: 5.9350\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.6488 - val_loss: 4.8048\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.4659 - val_loss: 5.7578\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2689 - val_loss: 5.2580\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 2.6377 - val_loss: 4.6610\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.1908 - val_loss: 5.6970\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.7842 - val_loss: 4.5735\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.5312 - val_loss: 4.6078\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 1.5653 - val_loss: 3.9838\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.3581 - val_loss: 4.3313\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 1.3673 - val_loss: 3.9601\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 1.4673 - val_loss: 4.4601\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 1.7096 - val_loss: 3.7079\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.6199 - val_loss: 3.8042\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.3837 - val_loss: 3.6557\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.6524 - val_loss: 3.9992\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.4513 - val_loss: 3.9044\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.0743 - val_loss: 4.0010\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.2329 - val_loss: 4.9397\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.3944 - val_loss: 4.2536\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.2106 - val_loss: 3.5366\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.1093 - val_loss: 4.5401\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.1506 - val_loss: 4.1197\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.9935 - val_loss: 3.5101\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.9413 - val_loss: 4.3365\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.9165 - val_loss: 5.2418\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.0786 - val_loss: 3.5317\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.0860 - val_loss: 3.4374\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.8814 - val_loss: 4.6853\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.1498 - val_loss: 4.1073\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.9761 - val_loss: 3.9298\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.8392 - val_loss: 3.2434\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.1230 - val_loss: 3.6756\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.1725 - val_loss: 3.4282\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.0494 - val_loss: 4.2191\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.9144 - val_loss: 3.4978\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.8583 - val_loss: 3.5280\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.0137 - val_loss: 4.0751\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.0143 - val_loss: 3.7489\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.2261 - val_loss: 4.3092\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.0067 - val_loss: 3.6798\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.0111 - val_loss: 3.8044\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5.6175\n",
      "1/1 [==============================] - 0s 433ms/step\n",
      "5.617496967315674\n",
      "(5, 47, 1)\n",
      "Fold 3:\n",
      "[1.0, 2.0, 7.0, 10.0, 11.0, 15.0, 29.0, 35.0, 36.0, 48.0, 55.0, 61.0, 67.0, 69.0, 72.0, 90.0, 91.0, 93.0, 97.0, 99.0, 102.0, 106.0, 107.0, 108.0, 110.0, 111.0, 113.0, 120.0, 126.0, 129.0, 136.0, 138.0, 141.0, 144.0, 152.0, 156.0, 161.0, 170.0, 173.0, 179.0] [183.0, 191.0, 193.0, 195.0, 197.0]\n",
      "[73.0, 75.0, 77.0, 80.0, 88.0]\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 47, 64)]          0         \n",
      "                                                                 \n",
      " masking_3 (Masking)         (None, 47, 64)            0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 47, 256)           328704    \n",
      "                                                                 \n",
      " layer_normalization_3 (Lay  (None, 47, 256)           94        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDi  (None, 47, 128)           32896     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDi  (None, 47, 1)             129       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 361823 (1.38 MB)\n",
      "Trainable params: 361823 (1.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 48ms/step - loss: 13.9898 - val_loss: 14.3668\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 8.3646 - val_loss: 10.2524\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.3774 - val_loss: 9.5641\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.0845 - val_loss: 7.0147\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 4.5275 - val_loss: 5.8545\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.4170 - val_loss: 5.2632\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.6241 - val_loss: 5.4527\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.6542 - val_loss: 6.6731\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.6523 - val_loss: 5.6777\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.4614 - val_loss: 4.7349\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.0486 - val_loss: 4.8709\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.9549 - val_loss: 4.9102\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.0222 - val_loss: 5.9706\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.5072 - val_loss: 5.2199\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.3871 - val_loss: 4.4768\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1675 - val_loss: 4.7148\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.4779 - val_loss: 6.1733\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.1111 - val_loss: 3.2867\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.9588 - val_loss: 6.8060\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 2.0886 - val_loss: 7.1550\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 2.0686 - val_loss: 3.2841\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.5358 - val_loss: 5.1754\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 1.5846 - val_loss: 3.5107\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 1.3017 - val_loss: 3.7697\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 2.1781 - val_loss: 4.6771\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 1.6471 - val_loss: 2.8357\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.6631 - val_loss: 3.6632\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.4284 - val_loss: 2.8287\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.2991 - val_loss: 2.5964\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.4389 - val_loss: 3.5813\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.3781 - val_loss: 4.1376\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.3956 - val_loss: 4.4587\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.2789 - val_loss: 4.1644\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 1.3543 - val_loss: 4.6096\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.1202 - val_loss: 4.4891\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.9979 - val_loss: 3.5443\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.2458 - val_loss: 6.0362\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.5233 - val_loss: 2.7710\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.6870 - val_loss: 5.9124\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5418\n",
      "1/1 [==============================] - 0s 437ms/step\n",
      "2.5418145656585693\n",
      "(5, 47, 1)\n",
      "Fold 4:\n",
      "[1.0, 2.0, 7.0, 10.0, 11.0, 15.0, 29.0, 35.0, 36.0, 48.0, 55.0, 61.0, 67.0, 69.0, 72.0, 73.0, 75.0, 77.0, 80.0, 88.0, 102.0, 106.0, 107.0, 108.0, 110.0, 111.0, 113.0, 120.0, 126.0, 129.0, 136.0, 138.0, 141.0, 144.0, 152.0, 156.0, 161.0, 170.0, 173.0, 179.0] [183.0, 191.0, 193.0, 195.0, 197.0]\n",
      "[90.0, 91.0, 93.0, 97.0, 99.0]\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 47, 64)]          0         \n",
      "                                                                 \n",
      " masking_4 (Masking)         (None, 47, 64)            0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 47, 256)           328704    \n",
      "                                                                 \n",
      " layer_normalization_4 (Lay  (None, 47, 256)           94        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDi  (None, 47, 128)           32896     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_9 (TimeDi  (None, 47, 1)             129       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 361823 (1.38 MB)\n",
      "Trainable params: 361823 (1.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 40ms/step - loss: 13.2130 - val_loss: 13.5606\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 7.6380 - val_loss: 9.7636\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.6015 - val_loss: 7.8288\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.8826 - val_loss: 7.1090\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.5057 - val_loss: 6.0633\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 4.1037 - val_loss: 6.9311\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 3.7216 - val_loss: 5.3430\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 3.5632 - val_loss: 7.3867\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 3.9772 - val_loss: 5.2760\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 4.0903 - val_loss: 6.9312\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 3.6607 - val_loss: 5.7732\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 3.2055 - val_loss: 5.0261\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 2.8254 - val_loss: 6.1217\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 2.5699 - val_loss: 6.3522\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 2.6959 - val_loss: 4.5335\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.5166 - val_loss: 4.1701\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.0940 - val_loss: 5.6233\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.6977 - val_loss: 3.3721\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.5250 - val_loss: 5.0530\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.8070 - val_loss: 6.6126\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.7495 - val_loss: 4.0908\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.6332 - val_loss: 5.1528\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.8003 - val_loss: 4.1197\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.3149 - val_loss: 3.8421\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.9391 - val_loss: 5.9173\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2364 - val_loss: 4.2045\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.9851 - val_loss: 3.3438\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.8251 - val_loss: 3.1052\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.5242 - val_loss: 3.2486\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.6052 - val_loss: 4.5940\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.5582 - val_loss: 6.3434\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.8134 - val_loss: 3.3666\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.2449 - val_loss: 3.8630\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.0595 - val_loss: 5.1782\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.0759 - val_loss: 5.2605\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.2116 - val_loss: 4.3479\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.9349 - val_loss: 3.6904\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.9413 - val_loss: 3.5677\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.4526\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x75c4e4459b40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 442ms/step\n",
      "6.452615261077881\n",
      "(5, 47, 1)\n",
      "Fold 5:\n",
      "[1.0, 2.0, 7.0, 10.0, 11.0, 15.0, 29.0, 35.0, 36.0, 48.0, 55.0, 61.0, 67.0, 69.0, 72.0, 73.0, 75.0, 77.0, 80.0, 88.0, 90.0, 91.0, 93.0, 97.0, 99.0, 111.0, 113.0, 120.0, 126.0, 129.0, 136.0, 138.0, 141.0, 144.0, 152.0, 156.0, 161.0, 170.0, 173.0, 179.0] [183.0, 191.0, 193.0, 195.0, 197.0]\n",
      "[102.0, 106.0, 107.0, 108.0, 110.0]\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 47, 64)]          0         \n",
      "                                                                 \n",
      " masking_5 (Masking)         (None, 47, 64)            0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 47, 256)           328704    \n",
      "                                                                 \n",
      " layer_normalization_5 (Lay  (None, 47, 256)           94        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " time_distributed_10 (TimeD  (None, 47, 128)           32896     \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_11 (TimeD  (None, 47, 1)             129       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 361823 (1.38 MB)\n",
      "Trainable params: 361823 (1.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 41ms/step - loss: 13.3774 - val_loss: 14.2171\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 8.0381 - val_loss: 10.2419\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.3253 - val_loss: 8.8596\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.9591 - val_loss: 7.3237\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.5373 - val_loss: 6.4265\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.3243 - val_loss: 7.3136\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.9179 - val_loss: 7.1137\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.4286 - val_loss: 6.6969\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.1506 - val_loss: 6.8553\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.9936 - val_loss: 5.1034\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.2419 - val_loss: 6.3898\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.8854 - val_loss: 5.3677\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.3598 - val_loss: 5.2111\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.6416 - val_loss: 6.1444\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.5277 - val_loss: 4.9145\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.3427 - val_loss: 4.5512\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1019 - val_loss: 6.8509\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2253 - val_loss: 5.4577\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.4880 - val_loss: 5.6637\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.2294 - val_loss: 7.7530\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.8849 - val_loss: 4.0081\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 3.0148 - val_loss: 5.1005\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.0874 - val_loss: 6.6431\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.7901 - val_loss: 4.4286\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.6193 - val_loss: 5.9115\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.8009 - val_loss: 5.1366\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.4120 - val_loss: 5.0638\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 1.2845 - val_loss: 5.3551\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 1.1048 - val_loss: 5.0667\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.1225 - val_loss: 5.7074\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.2065 - val_loss: 5.9561\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.2404\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x75c4e445bbe0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "4.2404255867004395\n",
      "(5, 47, 1)\n",
      "Fold 6:\n",
      "[1.0, 2.0, 7.0, 10.0, 11.0, 15.0, 29.0, 35.0, 36.0, 48.0, 55.0, 61.0, 67.0, 69.0, 72.0, 73.0, 75.0, 77.0, 80.0, 88.0, 90.0, 91.0, 93.0, 97.0, 99.0, 102.0, 106.0, 107.0, 108.0, 110.0, 136.0, 138.0, 141.0, 144.0, 152.0, 156.0, 161.0, 170.0, 173.0, 179.0] [183.0, 191.0, 193.0, 195.0, 197.0]\n",
      "[111.0, 113.0, 120.0, 126.0, 129.0]\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 47, 64)]          0         \n",
      "                                                                 \n",
      " masking_6 (Masking)         (None, 47, 64)            0         \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 47, 256)           328704    \n",
      "                                                                 \n",
      " layer_normalization_6 (Lay  (None, 47, 256)           94        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " time_distributed_12 (TimeD  (None, 47, 128)           32896     \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_13 (TimeD  (None, 47, 1)             129       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 361823 (1.38 MB)\n",
      "Trainable params: 361823 (1.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 49ms/step - loss: 11.9986 - val_loss: 13.1830\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 7.2575 - val_loss: 10.3284\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 5.6409 - val_loss: 8.9572\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.2746 - val_loss: 6.8739\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.8509 - val_loss: 6.1094\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.6019 - val_loss: 6.2915\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.6422 - val_loss: 7.3487\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.6543 - val_loss: 6.3614\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.1533 - val_loss: 5.6550\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.9803 - val_loss: 6.7156\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.8677 - val_loss: 6.8240\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.4978 - val_loss: 6.1049\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.9478 - val_loss: 8.4396\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.2384 - val_loss: 5.6731\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.3906 - val_loss: 5.7119\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 2.2510 - val_loss: 5.4467\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 1.8095 - val_loss: 4.9241\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.1504 - val_loss: 5.3252\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.3083 - val_loss: 6.9143\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.1790 - val_loss: 5.7825\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 2.1108 - val_loss: 4.3696\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.5654 - val_loss: 5.4902\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.5439 - val_loss: 4.4725\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.6615 - val_loss: 5.2665\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 1.7530 - val_loss: 4.2159\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 1.3232 - val_loss: 3.9439\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.2602 - val_loss: 4.3161\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.3483 - val_loss: 5.2165\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.5555 - val_loss: 5.3220\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.3368 - val_loss: 4.2496\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.2244 - val_loss: 4.1403\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.2602 - val_loss: 4.4425\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 1.3690 - val_loss: 3.6233\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.2718 - val_loss: 4.1888\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.0252 - val_loss: 3.3704\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.9672 - val_loss: 3.6687\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.0719 - val_loss: 3.8724\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.0818 - val_loss: 3.4472\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.9243 - val_loss: 4.3597\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.8380 - val_loss: 3.7546\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.8512 - val_loss: 4.3106\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.8833 - val_loss: 4.2779\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.0174 - val_loss: 3.5373\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.4807 - val_loss: 4.5461\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.1034 - val_loss: 3.7903\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.2377\n",
      "1/1 [==============================] - 0s 415ms/step\n",
      "7.237738132476807\n",
      "(5, 47, 1)\n",
      "Fold 7:\n",
      "[1.0, 2.0, 7.0, 10.0, 11.0, 15.0, 29.0, 35.0, 36.0, 48.0, 55.0, 61.0, 67.0, 69.0, 72.0, 73.0, 75.0, 77.0, 80.0, 88.0, 90.0, 91.0, 93.0, 97.0, 99.0, 102.0, 106.0, 107.0, 108.0, 110.0, 111.0, 113.0, 120.0, 126.0, 129.0, 156.0, 161.0, 170.0, 173.0, 179.0] [183.0, 191.0, 193.0, 195.0, 197.0]\n",
      "[136.0, 138.0, 141.0, 144.0, 152.0]\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 47, 64)]          0         \n",
      "                                                                 \n",
      " masking_7 (Masking)         (None, 47, 64)            0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 47, 256)           328704    \n",
      "                                                                 \n",
      " layer_normalization_7 (Lay  (None, 47, 256)           94        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " time_distributed_14 (TimeD  (None, 47, 128)           32896     \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_15 (TimeD  (None, 47, 1)             129       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 361823 (1.38 MB)\n",
      "Trainable params: 361823 (1.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 37ms/step - loss: 13.5313 - val_loss: 14.3820\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 8.0976 - val_loss: 11.0062\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.9875 - val_loss: 9.9615\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 4.8579 - val_loss: 7.9428\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.6928 - val_loss: 6.9837\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.9799 - val_loss: 6.2191\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.2554 - val_loss: 8.0483\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.7557 - val_loss: 6.7731\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 3.3232 - val_loss: 5.1892\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.6752 - val_loss: 7.9151\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.8967 - val_loss: 6.6401\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.2106 - val_loss: 6.0973\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.7147 - val_loss: 6.3654\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.4690 - val_loss: 5.9928\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.4831 - val_loss: 5.3318\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.5747 - val_loss: 6.0185\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1331 - val_loss: 6.3910\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.9497 - val_loss: 3.7199\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.9455 - val_loss: 4.1260\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.1070 - val_loss: 6.7513\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.5713 - val_loss: 3.7469\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.5316 - val_loss: 6.0256\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.1730 - val_loss: 5.5942\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.0089 - val_loss: 4.0264\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.6609 - val_loss: 5.1249\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.5302 - val_loss: 4.7751\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.3547 - val_loss: 3.7845\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.5144 - val_loss: 4.2765\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.8364\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "4.836357116699219\n",
      "(5, 47, 1)\n",
      "Fold 8:\n",
      "[1.0, 2.0, 7.0, 10.0, 11.0, 15.0, 29.0, 35.0, 36.0, 48.0, 55.0, 61.0, 67.0, 69.0, 72.0, 73.0, 75.0, 77.0, 80.0, 88.0, 90.0, 91.0, 93.0, 97.0, 99.0, 102.0, 106.0, 107.0, 108.0, 110.0, 111.0, 113.0, 120.0, 126.0, 129.0, 136.0, 138.0, 141.0, 144.0, 152.0] [183.0, 191.0, 193.0, 195.0, 197.0]\n",
      "[156.0, 161.0, 170.0, 173.0, 179.0]\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 47, 64)]          0         \n",
      "                                                                 \n",
      " masking_8 (Masking)         (None, 47, 64)            0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 47, 256)           328704    \n",
      "                                                                 \n",
      " layer_normalization_8 (Lay  (None, 47, 256)           94        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " time_distributed_16 (TimeD  (None, 47, 128)           32896     \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_17 (TimeD  (None, 47, 1)             129       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 361823 (1.38 MB)\n",
      "Trainable params: 361823 (1.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 42ms/step - loss: 12.9067 - val_loss: 13.7532\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 8.3262 - val_loss: 10.2924\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 6.1577 - val_loss: 10.2408\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 4.9182 - val_loss: 7.7978\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.7724 - val_loss: 6.7371\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 4.0668 - val_loss: 6.3551\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.8428 - val_loss: 8.0537\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.5541 - val_loss: 6.9861\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 3.6802 - val_loss: 4.9281\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 3.3906 - val_loss: 7.4305\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 3.4217 - val_loss: 5.2869\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 3.4098 - val_loss: 7.1491\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.7141 - val_loss: 6.4011\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.4397 - val_loss: 5.9910\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.7203 - val_loss: 5.4417\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 2.3609 - val_loss: 4.6223\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.2899 - val_loss: 7.1337\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 2.8755 - val_loss: 5.4489\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 2.7381 - val_loss: 5.2733\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.0934 - val_loss: 7.6276\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.2692 - val_loss: 4.4821\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.8565 - val_loss: 6.0170\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 1.7464 - val_loss: 3.6968\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.6842 - val_loss: 5.1318\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.6708 - val_loss: 4.4705\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.7749 - val_loss: 5.0726\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.3516 - val_loss: 3.8585\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.0979 - val_loss: 4.2858\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.1607 - val_loss: 5.2836\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.2887 - val_loss: 5.3182\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.1432 - val_loss: 4.6380\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.2241 - val_loss: 3.4407\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.2575 - val_loss: 6.7006\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.5658 - val_loss: 4.5521\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.4542 - val_loss: 4.7531\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.2909 - val_loss: 5.7165\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.8272 - val_loss: 4.1469\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.4492 - val_loss: 7.1501\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.4184 - val_loss: 3.4313\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.5575 - val_loss: 4.8556\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.4960 - val_loss: 5.1865\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.1276 - val_loss: 5.9852\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.1697 - val_loss: 5.2200\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.1462 - val_loss: 4.5264\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.2687 - val_loss: 5.5635\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.0001 - val_loss: 4.6582\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.9644 - val_loss: 4.4724\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.0508 - val_loss: 4.5481\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.0280 - val_loss: 4.3587\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.0299\n",
      "1/1 [==============================] - 0s 423ms/step\n",
      "4.029874801635742\n",
      "(5, 47, 1)\n",
      "Fold 9:\n",
      "[1.0, 2.0, 7.0, 10.0, 11.0, 15.0, 29.0, 35.0, 36.0, 48.0, 55.0, 61.0, 67.0, 69.0, 72.0, 73.0, 75.0, 77.0, 80.0, 88.0, 90.0, 91.0, 93.0, 97.0, 99.0, 102.0, 106.0, 107.0, 108.0, 110.0, 111.0, 113.0, 120.0, 126.0, 129.0, 136.0, 138.0, 141.0, 144.0, 152.0] [156.0, 161.0, 170.0, 173.0, 179.0]\n",
      "[183.0, 191.0, 193.0, 195.0, 197.0]\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 47, 64)]          0         \n",
      "                                                                 \n",
      " masking_9 (Masking)         (None, 47, 64)            0         \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 47, 256)           328704    \n",
      "                                                                 \n",
      " layer_normalization_9 (Lay  (None, 47, 256)           94        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " time_distributed_18 (TimeD  (None, 47, 128)           32896     \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_19 (TimeD  (None, 47, 1)             129       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 361823 (1.38 MB)\n",
      "Trainable params: 361823 (1.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 50ms/step - loss: 13.4629 - val_loss: 9.0872\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 8.4009 - val_loss: 5.3748\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.1199 - val_loss: 5.2118\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.0398 - val_loss: 3.4525\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.0155 - val_loss: 5.0602\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.4048 - val_loss: 3.6472\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.0982 - val_loss: 4.3569\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.8170 - val_loss: 4.3202\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.7582 - val_loss: 4.9686\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.4302 - val_loss: 3.8379\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.2213 - val_loss: 5.7448\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3.2723 - val_loss: 3.8576\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.8761 - val_loss: 4.1711\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.9477 - val_loss: 4.3624\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5.5165\n",
      "1/1 [==============================] - 0s 433ms/step\n",
      "5.516526222229004\n",
      "(5, 47, 1)\n"
     ]
    }
   ],
   "source": [
    "res_val = []\n",
    "err = []\n",
    "x_tr= []\n",
    "y_tr= []\n",
    "x_va = []\n",
    "y_va = []\n",
    "x_te= []\n",
    "y_te= []\n",
    "def main():\n",
    "    global res_val, x_tr, x_te, y_tr, y_te, x_va, y_va\n",
    "    # Start the cross Validation process\n",
    "    kf = KFold(n_splits=10)\n",
    "    kf.get_n_splits(pids)\n",
    "\n",
    "    #print(kf)\n",
    "    #train_pids = []\n",
    "    #test_pids = []\n",
    "    res_list = []\n",
    "    best_res = 9999999999.0\n",
    "    best_fold = ''\n",
    "    # CROSS VALIDAION\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(pids)):\n",
    "        print(f\"Fold {i}:\")\n",
    "        tr_pids = []\n",
    "        test_pids = []    \n",
    "        for j in train_index:\n",
    "            tr_pids.append(pids[j])\n",
    "        for k in test_index:\n",
    "            test_pids.append(pids[k])\n",
    "    \n",
    "        # Split training data into Training + Validation. \n",
    "        # Since we have 51 PIDS and 10 folds, we will assign 5 PIDs data to validation dataset.\n",
    "        train_pids = tr_pids[:-5]\n",
    "        val_pids   = tr_pids[-5:]\n",
    "\n",
    "        print(train_pids,val_pids)\n",
    "        print(test_pids)\n",
    "        \n",
    "        # In this block we want to read 5min avg temperature data for training, validation, and test PIDs\n",
    "        x_train, y_train = create_matrix_from_pid(train_pids)    \n",
    "        x_val  , y_val   = create_matrix_from_pid(val_pids)\n",
    "        x_test , y_test  = create_matrix_from_pid(test_pids)\n",
    "\n",
    "        x_tr = add_padding(x_train)\n",
    "        y_tr = add_padding(y_train)\n",
    "        x_va = add_padding(x_val)\n",
    "        y_va = add_padding(y_val)\n",
    "        x_te = add_padding(x_test)\n",
    "        y_te = add_padding(y_test)\n",
    "        \n",
    "        #print(x_tr.shape, x_va.shape, x_te.shape)\n",
    "\n",
    "        #lstm = define_lstm(47, 64)\n",
    "        lstm = define_lstm(max_seq_len, 64)\n",
    "        lstm.summary()\n",
    "        # Define Callbacks\n",
    "        early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "        # Compile the model using Adam optimizer and mean absolute error loss function.\n",
    "        lstm.compile(optimizer=keras.optimizers.Adam(), loss='mean_absolute_error')\n",
    "\n",
    "        # Need to add fold name here. Otherwise it'll overwrite.\n",
    "        checkpoint_filepath = './tmp/checkpointLSTM_'+ str(i)\n",
    "        check_point = keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_filepath,\n",
    "            save_weights_only=True,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_best_only=True)\n",
    "        \n",
    "        # Train the model for 100 epocs, batch size as 32, and use validation data for hyperparameter tuning.\n",
    "        history = lstm.fit(x_tr, y_tr,\n",
    "                        epochs=100,\n",
    "                        batch_size=2,\n",
    "                        callbacks = [early_stop,check_point],\n",
    "                        validation_data=(x_va, y_va))\n",
    "        # Save the Encoder model weights, to load and generate encodings later on.\n",
    "        lstm.save('./LSTM_weights/lstm_night_fold'+str(i)+'.keras')\n",
    "        \n",
    "        \n",
    "        # Run the Evaluate function on the test dataset.\n",
    "        res = lstm.evaluate(x_te,y_te)\n",
    "        res_v = lstm.predict(x_te)\n",
    "        res_val.append(res_v)\n",
    "        err.append(res)\n",
    "        print(res)\n",
    "        #for item in res_v:\n",
    "            #print((item))\n",
    "        print(res_v.shape)\n",
    "        \n",
    "    \n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8393b698-8e69-4b53-8c8f-a4570ad1e814",
   "metadata": {},
   "source": [
    "# Warning Message\n",
    "## Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
    "The resulting waring message might be caused due to the GPU architecture. The link below specifies that\n",
    "they do not see this type of error when GPU is disabled.\\\n",
    "[https://developer.apple.com/forums/thread/716638](https://developer.apple.com/forums/thread/716638)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e3f8c04-0fc0-42bf-af01-ccc452ceaa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.890251088142395\n"
     ]
    }
   ],
   "source": [
    "print(sum(err)/len(err)*1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f165c6e-43fe-4d03-9d61-6f452ee3db83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17073d7b-7e49-4bc3-af55-ea849160c7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PID:  1.0\n",
      "29 18\n",
      "Processing PID:  2.0\n",
      "20 18\n",
      "Processing PID:  7.0\n",
      "32 18\n",
      "Starting GA for PID is not 245, instead:  248.0\n",
      "Processing PID:  10.0\n",
      "42 18\n",
      "Processing PID:  11.0\n",
      "30 18\n",
      "Processing PID:  15.0\n",
      "28 18\n",
      "Starting GA for PID is not 245, instead:  259.0\n",
      "Processing PID:  29.0\n",
      "45 18\n",
      "Processing PID:  35.0\n",
      "33 18\n",
      "Processing PID:  36.0\n",
      "35 18\n",
      "Processing PID:  48.0\n",
      "29 18\n",
      "Processing PID:  55.0\n",
      "25 18\n",
      "Processing PID:  61.0\n",
      "23 18\n",
      "Processing PID:  67.0\n",
      "23 18\n",
      "Starting GA for PID is not 245, instead:  257.0\n",
      "Processing PID:  69.0\n",
      "41 18\n",
      "Processing PID:  72.0\n",
      "40 18\n",
      "Processing PID:  73.0\n",
      "28 18\n",
      "Processing PID:  75.0\n",
      "21 18\n",
      "Processing PID:  77.0\n",
      "29 18\n",
      "Processing PID:  80.0\n",
      "26 18\n",
      "Starting GA for PID is not 245, instead:  257.0\n",
      "Processing PID:  88.0\n",
      "38 18\n",
      "Processing PID:  90.0\n",
      "19 18\n",
      "Processing PID:  91.0\n",
      "20 18\n",
      "Processing PID:  93.0\n",
      "26 18\n",
      "Processing PID:  97.0\n",
      "36 18\n",
      "Processing PID:  99.0\n",
      "38 18\n",
      "Processing PID:  102.0\n",
      "30 18\n",
      "Processing PID:  106.0\n",
      "28 18\n",
      "Starting GA for PID is not 245, instead:  246.0\n",
      "Processing PID:  107.0\n",
      "45 18\n",
      "Processing PID:  108.0\n",
      "33 18\n",
      "Processing PID:  110.0\n",
      "25 18\n",
      "Processing PID:  111.0\n",
      "41 18\n",
      "Processing PID:  113.0\n",
      "29 18\n",
      "Starting GA for PID is not 245, instead:  250.0\n",
      "Processing PID:  120.0\n",
      "41 18\n",
      "Processing PID:  126.0\n",
      "24 18\n",
      "Processing PID:  129.0\n",
      "47 18\n",
      "Processing PID:  136.0\n",
      "16 18\n",
      "Processing PID:  138.0\n",
      "29 18\n",
      "Starting GA for PID is not 245, instead:  254.0\n",
      "Processing PID:  141.0\n",
      "46 18\n",
      "Processing PID:  144.0\n",
      "29 18\n",
      "Processing PID:  152.0\n",
      "34 18\n",
      "Processing PID:  156.0\n",
      "41 18\n",
      "Processing PID:  161.0\n",
      "28 18\n",
      "Processing PID:  170.0\n",
      "31 18\n",
      "Processing PID:  173.0\n",
      "25 18\n",
      "Starting GA for PID is not 245, instead:  254.0\n",
      "Processing PID:  179.0\n",
      "28 18\n",
      "Processing PID:  183.0\n",
      "43 18\n",
      "Processing PID:  191.0\n",
      "35 18\n",
      "Processing PID:  193.0\n",
      "46 18\n",
      "Processing PID:  195.0\n",
      "26 18\n",
      "Starting GA for PID is not 245, instead:  251.0\n",
      "Processing PID:  197.0\n",
      "37 18\n"
     ]
    }
   ],
   "source": [
    "# WRITING Predictions/Errors to an output CSV File.\n",
    "\n",
    "#print(len(err))\n",
    "# Convert res_val which contains all the predictions into an array \n",
    "res_arr = np.array(res_val)\n",
    "#print(res_arr.shape)\n",
    "#print(sum(err)/10.0)\n",
    "\n",
    "# Duplicate the split process.\n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(pids)\n",
    "total_mr = 0\n",
    "# Open a file for writing.\n",
    "fd = open('Fold_out.csv','w')\n",
    "# For Each Fold: i will go from 0 - 9\n",
    "for i, (train_index, test_index) in enumerate(kf.split(pids)):\n",
    "    test_pids = []\n",
    "    # Extract the test pid's from their indices\n",
    "    for j in test_index:\n",
    "        test_pids.append(pids[j])\n",
    "        \n",
    "    #print (test_pids)\n",
    "    test_len = len(test_pids)\n",
    "    for k in range(0,test_len):\n",
    "        print('Processing PID: ',test_pids[k])\n",
    "        # For each PID in the test set, read the input file corresponding to that PID\n",
    "        fname = os.path.join(exp_dir,str(int(test_pids[k]))+'_5temp_encoding.csv')\n",
    "        # Get total no. of rows in that file.\n",
    "        data = np.loadtxt(fname,delimiter=',')\n",
    "        # Extract last column, which is days till labor onset.\n",
    "        d2 = data[:,17:]\n",
    "        # mr is the total number of days of data starting from 245 for the PID.\n",
    "        mr,mc = data.shape\n",
    "        print (mr,mc)\n",
    "        total_mr += mr\n",
    "        # i - Fold, k - PID of the fold, 0-mr is valid days ignoring padding.\n",
    "        tmp = res_val[i][k][0:mr]\n",
    "        temp = tmp.reshape(1,mr)\n",
    "        #print(temp)\n",
    "        # First Write PID\n",
    "        fd.write(str(int(test_pids[k]))+',')\n",
    "        if data[0][0] != 245:\n",
    "            print('Starting GA for PID is not 245, instead: ',data[0][0])\n",
    "            start_diff = data[0][0] - 245 \n",
    "            for m in range(0,int(start_diff)):\n",
    "                fd.write(' ,')\n",
    "        # Write the absolute Error.\n",
    "        for l in range(0,len(temp[0])):\n",
    "            # Write model predictions.\n",
    "            #fd.write(str(abs(temp[0][l]))+',')\n",
    "            \n",
    "            # Difference of prediction - days to labor onset = Error\n",
    "            fd.write(str(abs(d2[l][0]- temp[0][l]))+',')\n",
    "        fd.write('\\n')\n",
    "\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cda97423-87a2-49f6-94dc-3350ca214d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PID:  1.0\n",
      "29 18\n",
      "Processing PID:  2.0\n",
      "20 18\n",
      "Processing PID:  7.0\n",
      "32 18\n",
      "Processing PID:  10.0\n",
      "42 18\n",
      "Processing PID:  11.0\n",
      "30 18\n",
      "Processing PID:  15.0\n",
      "28 18\n",
      "Processing PID:  29.0\n",
      "45 18\n",
      "Processing PID:  35.0\n",
      "33 18\n",
      "Processing PID:  36.0\n",
      "35 18\n",
      "Processing PID:  48.0\n",
      "29 18\n",
      "Processing PID:  55.0\n",
      "25 18\n",
      "Processing PID:  61.0\n",
      "23 18\n",
      "Processing PID:  67.0\n",
      "23 18\n",
      "Processing PID:  69.0\n",
      "41 18\n",
      "Processing PID:  72.0\n",
      "40 18\n",
      "Processing PID:  73.0\n",
      "28 18\n",
      "Processing PID:  75.0\n",
      "21 18\n",
      "Processing PID:  77.0\n",
      "29 18\n",
      "Processing PID:  80.0\n",
      "26 18\n",
      "Processing PID:  88.0\n",
      "38 18\n",
      "Processing PID:  90.0\n",
      "19 18\n",
      "Processing PID:  91.0\n",
      "20 18\n",
      "Processing PID:  93.0\n",
      "26 18\n",
      "Processing PID:  97.0\n",
      "36 18\n",
      "Processing PID:  99.0\n",
      "38 18\n",
      "Processing PID:  102.0\n",
      "30 18\n",
      "Processing PID:  106.0\n",
      "28 18\n",
      "Processing PID:  107.0\n",
      "45 18\n",
      "Processing PID:  108.0\n",
      "33 18\n",
      "Processing PID:  110.0\n",
      "25 18\n",
      "Processing PID:  111.0\n",
      "41 18\n",
      "Processing PID:  113.0\n",
      "29 18\n",
      "Processing PID:  120.0\n",
      "41 18\n",
      "Processing PID:  126.0\n",
      "24 18\n",
      "Processing PID:  129.0\n",
      "47 18\n",
      "Processing PID:  136.0\n",
      "16 18\n",
      "Processing PID:  138.0\n",
      "29 18\n",
      "Processing PID:  141.0\n",
      "46 18\n",
      "Processing PID:  144.0\n",
      "29 18\n",
      "Processing PID:  152.0\n",
      "34 18\n",
      "Processing PID:  156.0\n",
      "41 18\n",
      "Processing PID:  161.0\n",
      "28 18\n",
      "Processing PID:  170.0\n",
      "31 18\n",
      "Processing PID:  173.0\n",
      "25 18\n",
      "Processing PID:  179.0\n",
      "28 18\n",
      "Processing PID:  183.0\n",
      "43 18\n",
      "Processing PID:  191.0\n",
      "35 18\n",
      "Processing PID:  193.0\n",
      "46 18\n",
      "Processing PID:  195.0\n",
      "26 18\n",
      "Processing PID:  197.0\n",
      "37 18\n"
     ]
    }
   ],
   "source": [
    "# OUTPUT RELATIVE TO LABOR DATE\n",
    "\n",
    "# Convert res_val which contains all the predictions into an array \n",
    "res_arr = np.array(res_val)\n",
    "#print(res_arr.shape)\n",
    "#print(sum(err)/10.0)\n",
    "\n",
    "# Duplicate the split process.\n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(pids)\n",
    "\n",
    "# What is the maximum days before labor we are predicting results?\n",
    "max_ld = 46\n",
    "\n",
    "# Open a file for writing.\n",
    "fd = open('Fold_out.csv','w')\n",
    "# For Each Fold: i will go from 0 - 9\n",
    "for i, (train_index, test_index) in enumerate(kf.split(pids)):\n",
    "    test_pids = []\n",
    "    # Extract the test pid's from their indices\n",
    "    for j in test_index:\n",
    "        test_pids.append(pids[j])\n",
    "        \n",
    "    #print (test_pids)\n",
    "    test_len = len(test_pids)\n",
    "    for k in range(0,test_len):\n",
    "        print('Processing PID: ',test_pids[k])\n",
    "        # For each PID in the test set, read the input file corresponding to that PID\n",
    "        fname = os.path.join(exp_dir,str(int(test_pids[k]))+'_5temp_encoding.csv')\n",
    "        # Get total no. of rows in that file.\n",
    "        data = np.loadtxt(fname,delimiter=',')\n",
    "        # Extract last column, which is days till labor onset.\n",
    "        d2 = data[:,17:]\n",
    "        # mr is the total number of days of data starting from 245 for the PID.\n",
    "        mr,mc = data.shape\n",
    "        print (mr,mc)\n",
    "\n",
    "        # i - Fold, k - PID of the fold, 0-mr is valid days ignoring padding.\n",
    "        tmp = res_val[i][k][0:mr]\n",
    "        temp = tmp.reshape(1,mr)\n",
    "        #print(temp)\n",
    "        # First Write PID\n",
    "        fd.write(str(int(test_pids[k]))+',')\n",
    "        \n",
    "        start_diff = 46 - d2[0][0] \n",
    "        for m in range(0,int(start_diff)):\n",
    "                fd.write(' ,')\n",
    "        # Write the absolute Error.\n",
    "        for l in range(0,len(temp[0])):\n",
    "            # Write model predictions.\n",
    "            fd.write(str(abs(temp[0][l]))+',')\n",
    "            \n",
    "            # Difference of prediction - days to labor onset = Error\n",
    "            #fd.write(str(abs(d2[l][0]- temp[0][l]))+',')\n",
    "            #fd.write(str(d2[l][0]- temp[0][l])+',')\n",
    "        fd.write('\\n')\n",
    "\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b55653aa-e586-4687-8294-7373d2351403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1593\n"
     ]
    }
   ],
   "source": [
    "print(total_mr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b00dd7-8786-4260-99ad-2d371cd4ba12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
